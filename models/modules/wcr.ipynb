{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## {'_name': 'ecg_transformer_classifier', 'all_gather': False, 'normalize': False, 'filter': False, 'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/finetune_acs/', 'args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 25, 'log_format': 'json', 'log_file': None, 'wandb_project': 'wav2vec2-pretraining', 'wandb_entity': None, 'seed': 1, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'quiet': False, 'model_overrides': '{}', 'save_outputs': False, 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 3, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12440', 'distributed_port': 12355, 'device_id': 0, 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'fp16': True, 'memory_efficient_fp16': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 342, 'required_batch_size_multiple': 8, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': '', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 342, 'max_valid_steps': None, 'curriculum': 0, 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 0, 'lr': [5e-05], 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'update_freq': [2], 'stop_min_lr': -1.0}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints-50k', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False}, 'model': {'_name': 'wav2vec2_cmsc', 'all_gather': False, 'normalize': False, 'filter': False, 'data': '/media/data1/achilsowa/datasets/mhi/preprocess/train-50k/manifest/cmsc/', 'args': None, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'layer_norm_first': False, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'extractor_mode': 'default', 'conv_feature_layers': '[(256, 2, 2)] * 4', 'in_d': 12, 'conv_bias': False, 'feature_grad_mult': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'logit_temp': 0.1, 'quantize_targets': True, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'final_dim': 256, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'latent_temp': [2.0, 0.5, 0.999995]}, 'task': {'_name': 'ecg_pretraining', 'data': '/media/data1/achilsowa/datasets/mhi/preprocess/train-50k/manifest/cmsc/', 'leads_to_load': None, 'leads_bucket': None, 'bucket_selection': 'uniform', 'sample_rate': None, 'filter': False, 'normalize': False, 'mean_path': None, 'std_path': None, 'enable_padding': True, 'enable_padding_leads': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'perturbation_mode': ['random_leads_masking'], 'p': [1.0], 'max_amplitude': 0.1, 'min_amplitude': 0.0, 'dependency': True, 'shift_ratio': 0.2, 'num_segment': 1, 'max_freq': 0.2, 'min_freq': 0.01, 'k': 3, 'mask_leads_selection': 'random', 'mask_leads_prob': 0.5, 'mask_leads_condition': [4, 5], 'inferred_w2v_config': None, 'inferred_3kg_config': None, 'criterion_name': 'wav2vec2_with_cmsc', 'model_name': None, 'clocs_mode': None}, 'criterion': None, 'lr_scheduler': None, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'lr': [5e-05]}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'layer_norm_first': False, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'apply_mask': False, 'mask_length': 10, 'mask_prob': 0.0, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'extractor_mode': 'default', 'conv_feature_layers': '[(256, 2, 2)] * 4', 'in_d': 12, 'conv_bias': False, 'feature_grad_mult': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'model_path': '/volume/deepecg/fairseq-signals/outputs/2024-08-22/14-31-06/checkpoints-50k/checkpoint_last.pt', 'no_pretrained_weights': False, 'freeze_finetune_updates': 0, 'final_dropout': 0.0, 'num_labels': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "# import useful old code\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import importlib\n",
    "import math\n",
    "\n",
    "project_dir = os.path.abspath(\"/volume/deepecg/fairseq-signals\")\n",
    "root_dir = project_dir #os.path.dirname(project_dir)\n",
    "if not root_dir in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"checkpoint_utils\", f\"{project_dir}/fairseq_signals/utils/checkpoint_utils.py\")\n",
    "checkpoint_utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(checkpoint_utils)\n",
    "\n",
    "\n",
    "overrides = {'task': {'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/finetune_acs/'}}\n",
    "\n",
    "model, saved_cfg, task = checkpoint_utils.load_model_and_task(\n",
    "    \"/volume/deepecg/fairseq-signals/outputs/2024-09-05/17-43-03/checkpoints/checkpoint_best.pt\",\n",
    "    arg_overrides=overrides,\n",
    "    suffix=''\n",
    ")\n",
    "#save_path = os.path.join(os.path.dirname(cfg.common_eval.path), 'model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder_out': tensor([[[-0.4216,  0.2183,  0.4057,  ..., -0.9224,  1.5248, -0.5166],\n",
       "          [-0.1262,  0.2373,  0.4584,  ..., -0.7339,  1.4726, -0.3538],\n",
       "          [-0.2803,  0.2943,  0.4748,  ..., -0.9152,  1.3633, -0.4681],\n",
       "          ...,\n",
       "          [-0.2931,  0.2564,  0.4334,  ..., -0.6728,  1.5090, -0.4866],\n",
       "          [-0.3147,  0.2330,  0.2427,  ..., -0.9734,  1.4349, -0.5782],\n",
       "          [-0.3350,  0.1635,  0.2540,  ..., -0.7897,  1.3578, -0.5407]],\n",
       " \n",
       "         [[-0.3118,  0.2477,  0.1127,  ..., -0.7407,  1.4564, -0.6096],\n",
       "          [-0.3430,  0.0428,  0.2153,  ..., -0.7782,  1.2055, -0.4416],\n",
       "          [-0.3474,  0.3030,  0.4393,  ..., -0.8570,  1.3565, -0.7797],\n",
       "          ...,\n",
       "          [-0.2115,  0.1953,  0.3790,  ..., -0.7188,  1.3513, -0.4364],\n",
       "          [-0.3219,  0.2125,  0.3240,  ..., -0.8093,  1.3797, -0.6796],\n",
       "          [-0.1509,  0.1534,  0.4601,  ..., -0.8682,  1.3689, -0.5476]],\n",
       " \n",
       "         [[-0.2257,  0.2255,  0.3174,  ..., -0.7212,  1.1182, -0.4055],\n",
       "          [-0.4369,  0.2007,  0.2167,  ..., -0.6495,  1.2746, -0.4314],\n",
       "          [-0.2370,  0.1138,  0.2708,  ..., -0.8644,  1.3963, -0.4163],\n",
       "          ...,\n",
       "          [-0.2736,  0.2597,  0.4513,  ..., -0.7347,  1.3527, -0.3089],\n",
       "          [-0.2212,  0.1525,  0.3719,  ..., -0.8615,  1.5635, -0.4230],\n",
       "          [-0.0925,  0.4393,  0.3750,  ..., -0.7603,  1.5188, -0.3621]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.2933, -0.0561,  0.4447,  ..., -0.8391,  1.3559, -0.6110],\n",
       "          [-0.3138, -0.0252,  0.4343,  ..., -0.9350,  1.2763, -0.3487],\n",
       "          [-0.1933,  0.1954,  0.4750,  ..., -0.8367,  1.3616, -0.6015],\n",
       "          ...,\n",
       "          [-0.2919,  0.1497,  0.4468,  ..., -0.6452,  1.4330, -0.3983],\n",
       "          [-0.2043,  0.1969,  0.4693,  ..., -0.8238,  1.4105, -0.6387],\n",
       "          [-0.2990,  0.1755,  0.4045,  ..., -0.7257,  1.3073, -0.4497]],\n",
       " \n",
       "         [[-0.2025,  0.0388,  0.5518,  ..., -0.7568,  1.3210, -0.5150],\n",
       "          [-0.2458,  0.1635,  0.3177,  ..., -0.9768,  1.2535, -0.4603],\n",
       "          [-0.5039,  0.2425,  0.2075,  ..., -0.7243,  1.4514, -0.5747],\n",
       "          ...,\n",
       "          [-0.2338,  0.2650,  0.1819,  ..., -0.5507,  1.4798, -0.6170],\n",
       "          [-0.3193,  0.0319,  0.5299,  ..., -0.5002,  1.3818, -0.3554],\n",
       "          [-0.1669,  0.0588,  0.3483,  ..., -0.8807,  1.5459, -0.3980]],\n",
       " \n",
       "         [[-0.0434,  0.3501,  0.4275,  ..., -0.7462,  1.4978, -0.3324],\n",
       "          [-0.2385,  0.2904,  0.2877,  ..., -0.7615,  1.2227, -0.6099],\n",
       "          [-0.1436,  0.0821,  0.4533,  ..., -0.5879,  1.3401, -0.3000],\n",
       "          ...,\n",
       "          [-0.3527,  0.0700,  0.2378,  ..., -0.5809,  1.1374, -0.4345],\n",
       "          [-0.2264,  0.1477,  0.3713,  ..., -0.6219,  1.3682, -0.4666],\n",
       "          [-0.2794,  0.2160,  0.2778,  ..., -0.8463,  1.3943, -0.5341]]]),\n",
       " 'padding_mask': None,\n",
       " 'out': tensor([[-0.1261],\n",
       "         [ 0.1052],\n",
       "         [-0.4005],\n",
       "         [-0.4213],\n",
       "         [-0.4336],\n",
       "         [-0.4369],\n",
       "         [-0.3376],\n",
       "         [ 0.1782],\n",
       "         [-0.7668],\n",
       "         [-0.8128]], grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "B = 10\n",
    "net_input = {\n",
    "    \"source\": torch.randn(B, 12, 2500)\n",
    "}\n",
    "net_output = model(**net_input)\n",
    "logits_shape = (B,) + tuple(model.get_logits(net_output).shape[1:])\n",
    "\n",
    "net_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
