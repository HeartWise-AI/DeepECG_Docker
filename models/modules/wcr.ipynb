{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## {'_name': 'ecg_transformer_classifier', 'all_gather': False, 'normalize': False, 'filter': False, 'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/finetune_afib/', 'args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 25, 'log_format': 'json', 'log_file': None, 'wandb_project': 'wav2vec2-pretraining', 'wandb_entity': None, 'seed': 1, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'quiet': False, 'model_overrides': '{}', 'save_outputs': False, 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 3, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10031', 'distributed_port': 12355, 'device_id': 0, 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'fp16': True, 'memory_efficient_fp16': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 342, 'required_batch_size_multiple': 8, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': '', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 342, 'max_valid_steps': None, 'curriculum': 0, 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 0, 'lr': [5e-05], 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'update_freq': [2], 'stop_min_lr': -1.0}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints-all', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False}, 'model': {'_name': 'wav2vec2_cmsc', 'all_gather': False, 'normalize': False, 'filter': False, 'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/cmsc/', 'args': None, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'layer_norm_first': False, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'extractor_mode': 'default', 'conv_feature_layers': '[(256, 2, 2)] * 4', 'in_d': 12, 'conv_bias': False, 'feature_grad_mult': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'logit_temp': 0.1, 'quantize_targets': True, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'final_dim': 256, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'latent_temp': [2.0, 0.5, 0.999995]}, 'task': {'_name': 'ecg_pretraining', 'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/cmsc/', 'leads_to_load': None, 'leads_bucket': None, 'bucket_selection': 'uniform', 'sample_rate': None, 'filter': False, 'normalize': False, 'mean_path': None, 'std_path': None, 'enable_padding': True, 'enable_padding_leads': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'perturbation_mode': ['random_leads_masking'], 'p': [1.0], 'max_amplitude': 0.1, 'min_amplitude': 0.0, 'dependency': True, 'shift_ratio': 0.2, 'num_segment': 1, 'max_freq': 0.2, 'min_freq': 0.01, 'k': 3, 'mask_leads_selection': 'random', 'mask_leads_prob': 0.5, 'mask_leads_condition': [4, 5], 'inferred_w2v_config': None, 'inferred_3kg_config': None, 'criterion_name': 'wav2vec2_with_cmsc', 'model_name': None, 'clocs_mode': None}, 'criterion': None, 'lr_scheduler': None, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'lr': [5e-05]}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'layer_norm_first': False, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'apply_mask': False, 'mask_length': 10, 'mask_prob': 0.0, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'extractor_mode': 'default', 'conv_feature_layers': '[(256, 2, 2)] * 4', 'in_d': 12, 'conv_bias': False, 'feature_grad_mult': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'model_path': '/volume/deepecg/fairseq-signals/outputs/2024-09-05/13-40-53/checkpoints-all/checkpoint_last.pt', 'no_pretrained_weights': False, 'freeze_finetune_updates': 0, 'final_dropout': 0.0, 'num_labels': 2}\n",
      "########## {'_name': 'ecg_transformer_classifier', 'all_gather': False, 'normalize': False, 'filter': False, 'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/finetune_fevg/', 'args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 25, 'log_format': 'json', 'log_file': None, 'wandb_project': 'wav2vec2-pretraining', 'wandb_entity': None, 'seed': 1, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'quiet': False, 'model_overrides': '{}', 'save_outputs': False, 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 3, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10031', 'distributed_port': 12355, 'device_id': 0, 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'fp16': True, 'memory_efficient_fp16': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 342, 'required_batch_size_multiple': 8, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': '', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 342, 'max_valid_steps': None, 'curriculum': 0, 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 0, 'lr': [5e-05], 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'update_freq': [2], 'stop_min_lr': -1.0}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints-all', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False}, 'model': {'_name': 'wav2vec2_cmsc', 'all_gather': False, 'normalize': False, 'filter': False, 'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/cmsc/', 'args': None, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'layer_norm_first': False, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'extractor_mode': 'default', 'conv_feature_layers': '[(256, 2, 2)] * 4', 'in_d': 12, 'conv_bias': False, 'feature_grad_mult': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'logit_temp': 0.1, 'quantize_targets': True, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'final_dim': 256, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'latent_temp': [2.0, 0.5, 0.999995]}, 'task': {'_name': 'ecg_pretraining', 'data': '/media/data1/achilsowa/datasets/fairseq/mhi/manifest/cmsc/', 'leads_to_load': None, 'leads_bucket': None, 'bucket_selection': 'uniform', 'sample_rate': None, 'filter': False, 'normalize': False, 'mean_path': None, 'std_path': None, 'enable_padding': True, 'enable_padding_leads': False, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'perturbation_mode': ['random_leads_masking'], 'p': [1.0], 'max_amplitude': 0.1, 'min_amplitude': 0.0, 'dependency': True, 'shift_ratio': 0.2, 'num_segment': 1, 'max_freq': 0.2, 'min_freq': 0.01, 'k': 3, 'mask_leads_selection': 'random', 'mask_leads_prob': 0.5, 'mask_leads_condition': [4, 5], 'inferred_w2v_config': None, 'inferred_3kg_config': None, 'criterion_name': 'wav2vec2_with_cmsc', 'model_name': None, 'clocs_mode': None}, 'criterion': None, 'lr_scheduler': None, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'lr': [5e-05]}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'layer_norm_first': False, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'apply_mask': False, 'mask_length': 10, 'mask_prob': 0.0, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'extractor_mode': 'default', 'conv_feature_layers': '[(256, 2, 2)] * 4', 'in_d': 12, 'conv_bias': False, 'feature_grad_mult': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'model_path': '/volume/deepecg/fairseq-signals/outputs/2024-09-05/13-40-53/checkpoints-all/checkpoint_last.pt', 'no_pretrained_weights': False, 'freeze_finetune_updates': 0, 'final_dropout': 0.0, 'num_labels': 2}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "m_root = '/media/data1/achilsowa/results/fairseq/outputs/'\n",
    "\n",
    "m_paths = {\n",
    "    \"FT_AFIB\": os.path.join(m_root, \"2024-09-09/02-29-11/checkpoints-afib/checkpoint_best.pt\"),\n",
    "    \"FT_FEVG\": os.path.join(m_root, \"2024-09-08/18-37-44/checkpoints/checkpoint_best.pt\")\n",
    "}\n",
    "\n",
    "# Get the path to the root directory of your project\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # Adjust according to your folder depth\n",
    "\n",
    "# Add the root directory to sys.path\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "from models.modules.wcr import WCREcgTransformer\n",
    "\n",
    "\n",
    "model_afib = WCREcgTransformer(m_paths['FT_AFIB'])\n",
    "model_fevg = WCREcgTransformer(m_paths['FT_FEVG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 12, 2500]), torch.Size([10, 2]), torch.Size([10, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 10\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(B, 12, 2500)\n",
    "y_afib_logits, _ = model_afib(x)\n",
    "y_fevg_logits, _ = model_fevg(x)\n",
    "\n",
    "x.shape, y_afib_logits.shape, y_fevg_logits.shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
